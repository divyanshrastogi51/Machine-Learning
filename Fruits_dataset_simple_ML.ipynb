{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import required modules and load data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "fruits = pd.read_table('fruit_data_with_colors.txt')\n",
    "df = fruits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fruits.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple  K-NN classifier model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5333333333333333"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup_fruit_name = dict(zip(fruits.fruit_label.unique(), fruits.fruit_name.unique()))\n",
    "X = fruits[['mass', 'width', 'height','color_score']]\n",
    "y = fruits['fruit_label']\n",
    "# default is 75% / 25% train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "#Create classifier object\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "#Train the classifier (fit the estimator) using the training data\n",
    "knn.fit(X_train, y_train)\n",
    "#Estimate the accuracy of the classifier on future data, using the test data\n",
    "knn.score(X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How sensitive is k-NN classification accuracy to the choice of the 'k' parameter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k_range = range(1,20)\n",
    "scores = []\n",
    "\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    scores.append(knn.score(X_test, y_test))\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('accuracy')\n",
    "plt.scatter(k_range, scores)\n",
    "plt.xticks([0,5,10,15,20]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How sensitive is k-NN classification accuracy to the train/test split proportion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t = [0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2]\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "for s in t:\n",
    "\n",
    "    scores = []\n",
    "    for i in range(1,1000):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1-s)\n",
    "        knn.fit(X_train, y_train)\n",
    "        scores.append(knn.score(X_test, y_test))\n",
    "    plt.plot(s, np.mean(scores), 'bo')\n",
    "\n",
    "plt.xlabel('Training set proportion (%)')\n",
    "plt.ylabel('accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the trained k-NN classifier model to classify new, previously unseen objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# first example: a small fruit with mass 20g, width 4.3 cm, height 5.5 cm\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "knn.fit(X_train, y_train)\n",
    "knn.score(X_test, y_test)\n",
    "\n",
    "fruit_prediction = knn.predict([[100, 6.3, 8.5,.7]])\n",
    "lookup_fruit_name[fruit_prediction[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using MINMAX Scaler for feature to have a normal distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "# we must apply the scaling to the test set that we computed for the training set\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "print('Accuracy of K-NN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train_scaled, y_train)))\n",
    "print('Accuracy of K-NN classifier on test set: {:.2f}'\n",
    "     .format(knn.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remember that here test data will also be transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target_names_fruits = ['apple', 'mandarin', 'orange', 'lemon']\n",
    "example_fruit = [[10, 2.2, 5.5, 0.7]]\n",
    "example_fruit_scaled = scaler.transform(example_fruit)\n",
    "print('Predicted fruit type for ', example_fruit, ' is ', \n",
    "          target_names_fruits[knn.predict(example_fruit_scaled)[0]-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear models for classification\n",
    "## Logistic regression\n",
    "### Logistic regression for binary classification on fruits dataset using height, width features,(positive class: apple, negative class: others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A fruit with height 6 and width 8 is predicted to be: an apple\n",
      "A fruit with height 10 and width 7 is predicted to be: not an apple\n",
      "Accuracy of Logistic regression classifier on training set: 0.80\n",
      "Accuracy of Logistic regression classifier on test set: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\divyanshrastogi\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  \n",
      "C:\\Users\\divyanshrastogi\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_fruits_2d = fruits[['height', 'width']]\n",
    "y_fruits_2d = fruits['fruit_label']\n",
    "\n",
    "y_fruits_apple = y_fruits_2d == 1   # make into a binary problem: apples vs everything else\n",
    "X_train, X_test, y_train, y_test = (\n",
    "train_test_split(X_fruits_2d, y_fruits_apple,random_state = 0))\n",
    "clf = LogisticRegression(C=100).fit(X_train, y_train)\n",
    "\n",
    "h = 6\n",
    "w = 8\n",
    "print('A fruit with height {} and width {} is predicted to be: {}'\n",
    "     .format(h,w, ['not an apple', 'an apple'][clf.predict([[h,w]])[0]]))\n",
    "\n",
    "h = 10\n",
    "w = 7\n",
    "print('A fruit with height {} and width {} is predicted to be: {}'\n",
    "     .format(h,w, ['not an apple', 'an apple'][clf.predict([[h,w]])[0]]))\n",
    "print('Accuracy of Logistic regression classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))\n",
    "print('Accuracy of Logistic regression classifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores (3-fold): [0.75 0.75 0.83 0.83 0.82]\n",
      "Mean cross-validation score (3-fold): 0.797\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors = 5)\n",
    "X = X_fruits_2d\n",
    "y = y_fruits_2d\n",
    "cv_scores = cross_val_score(clf, X, y)\n",
    "\n",
    "print('Cross-validation scores (3-fold):', cv_scores)\n",
    "print('Mean cross-validation score (3-fold): {:.3f}'\n",
    "     .format(np.mean(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
